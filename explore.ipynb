{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook para el análisis exploratorio del datathon"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_meteo = pd.read_csv('inputs/meteo_valencia.csv', sep=';')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Definición de los días festivos en la Comunidad Valenciana para el año 2019 y el primer mes de 2020\n",
    "FESTIVOS = [\n",
    "    '2019-03-19', '2019-04-19', '2019-04-22','2019-04-29', '2019-05-01', '2019-06-24', '2019-08-15','2019-10-09','2019-10-12','2019-11-01',\n",
    "    '2019-12-06','2019-12-25','2020-01-01','2020-01-22'\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DATASET: Meteorología Valencia"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Corrección de errores de escritura \n",
    "En el dataset de meteorología de Valencia tanto las temperaturas como las precipitaciones tienen puntos y comas como delimitadores decimales. \n",
    "Lo que se hace es sustituir la coma por un punto para después poder transformar la columna a tipo float"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def change_decimal_delim(df_meteo: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    for column in columns:\n",
    "        df_meteo[column] = df_meteo[column].astype(str)\n",
    "        df_meteo[column].replace({',':'.','nan':np.nan, ' ':np.nan, '':np.nan}, inplace=True, regex=True)\n",
    "        df_meteo[column].fillna(0, inplace=True)\n",
    "        df_meteo[column]= df_meteo[column].astype(float)\n",
    "        df_meteo[column].replace(0.0, np.nan, inplace=True)\n",
    "    return df_meteo\n",
    "    \n",
    "df_meteo = change_decimal_delim(df_meteo, ['Temp.', 'Precip.'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generación de una nueva columna de fecha (Date) en formato YYYY-MM-DD para poder unir después los dos datasets por la fecha"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dict_meses ={\n",
    "    'Enero': '01', 'Febrero':'02', 'Marzo':'03', 'Abril':'04', 'Mayo':'05', 'Junio':'06', 'Julio':'07', 'Agosto':'08', 'Septiembre':'09',\n",
    "    'Octubre':'10', 'Noviembre':'11', 'Diciembre':'12' \n",
    "}\n",
    "df_meteo[['Year', 'Día']] = df_meteo[['Year', 'Día']].astype(str)\n",
    "df_meteo['Mes'] = df_meteo['Mes'].apply(lambda x: dict_meses[x])\n",
    "df_meteo['Date'] = df_meteo[['Year', 'Mes', 'Día']].agg('-'.join, axis=1)\n",
    "df_meteo['Date'] = pd.to_datetime(df_meteo['Date'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Se crea el dataframe de meteorología para Valencia tomando la media de la temperatura y las precipitaciones\n",
    "# en todas las estaciones meteorológicas para cada día\n",
    "df_meteo = df_meteo.groupby('Date')[['Temp.', 'Precip.']].mean()\n",
    "df_meteo.reset_index(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filtro para seleccionar las mismas fechas que en el dataset de Cajamar\n",
    "df_meteo = df_meteo[(df_meteo['Date']>='2019-02-01') & (df_meteo['Date']<='2020-01-31')]\n",
    "df_meteo.fillna(0, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Relación entre las precipitaciones y la temperatura en Valencia. \n",
    "Se puede apreciar que no hay excesivas precipitaciones en la Comunidad Valenciana y parece que el hecho de que la temperatura aumente hace que las precipitaciones bajen puesto que en los meses estivales las precipitaciones son mucho menores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = go.Figure()\n",
    "# add line / trace 1 to figure: Temperatura\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_meteo['Date'],\n",
    "    y=df_meteo['Temp.'],\n",
    "    marker=dict(\n",
    "        color=\"blue\"\n",
    "    ),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# add line / trace 2 to figure: Precipitaciones\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_meteo['Date'],\n",
    "    y=df_meteo['Precip.'],\n",
    "    marker=dict(\n",
    "        color=\"green\"\n",
    "    ),\n",
    "    showlegend=False\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Distribución de la temperatura y las precipitaciones\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Precipitaciones y temperatura\"\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DATASET: Cajamar Demanda\n",
    "\n",
    "El dataset contiene demandas desde 2019-02-01 hasta 2020-01-31"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_demanda = pd.read_csv('inputs/Modelar_UH2022.txt', sep='|')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hay dos contadores que tienen datos anómalos. Los contadores dan valores negativos, por lo tanto se descartan estos dos contadores para el analisis de la estimación de la demanda"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_demanda.groupby('ID')[['READINGINTEGER']].sum().sort_values(by='READINGINTEGER')\n",
    "df_demanda = df_demanda[~df_demanda['ID'].isin([1041, 2711])]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generacion de dos nuevas columnas que son la separación de la fecha en fecha y hora\n",
    "df_demanda[['Date', 'Hour']] = df_demanda['SAMPLETIME'].str.split(' ', 1, expand=True)\n",
    "df_demanda['Date'] = df_demanda['Date'].astype('datetime64')\n",
    "df_demanda.drop(['SAMPLETIME'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Columna de decimales a integer para quitarle los .0 y luego se los pongo yo manualmente a todos. Despues se crea una sola\n",
    "# columna de lectura real del contador\n",
    "\n",
    "def clean_cols(df: pd.DataFrame, coltoclean:list) -> pd.DataFrame:\n",
    "    if coltoclean == 'DELTATHOUSANDTH':\n",
    "        df_demanda[coltoclean] = df_demanda[coltoclean].apply(lambda x: re.sub(r'[^0-9.]', '', str(x)))\n",
    "        df_demanda[coltoclean].fillna('0', inplace=True)\n",
    "    else:\n",
    "        df_demanda[coltoclean].fillna(0.0, inplace=True)\n",
    "    df_demanda[coltoclean] = df_demanda[coltoclean].astype(float).astype(int)\n",
    "    df_demanda[coltoclean] = df_demanda[coltoclean].apply(lambda x: f\"0.{x}\")\n",
    "    df_demanda[coltoclean] = df_demanda[coltoclean].astype(float)\n",
    "    return df_demanda\n",
    "\n",
    "df_demanda = clean_cols(df_demanda, 'READINGTHOUSANDTH')\n",
    "df_demanda['lectura_contador'] = df_demanda['READINGINTEGER'] + df_demanda['READINGTHOUSANDTH']\n",
    "df_demanda = clean_cols(df_demanda, 'DELTATHOUSANDTH')\n",
    "df_demanda['consumo_calculado']= df_demanda['DELTAINTEGER'].astype(int) + df_demanda['DELTATHOUSANDTH']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Diferencias entre consumos reales y calculados\n",
    "Para poder determinar que columna utilizar como estimador se observan las diferencias entre el consumo real diario (lectura de los contadores) y el consumo calculado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_demanda = df_demanda.sort_values(by=['Hour'])\n",
    "df_contadores = df_demanda.groupby(['ID', 'Date'])['lectura_contador'].agg(['first','last']).reset_index()\n",
    "df_contadores['consumo_real'] = df_contadores['last'] - df_contadores['first']\n",
    "df_calculados = df_demanda.groupby(['ID', 'Date'])['consumo_calculado'].sum().reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_consumos = pd.merge(df_contadores, df_calculados, on=['ID', 'Date'], how='inner')\n",
    "df_consumos['Diferencias_consumo'] = df_consumos['consumo_real'] - df_consumos['consumo_calculado']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Eliminar valores negativos o valores sin sentido de consumo\n",
    "Hay varios casos:\n",
    "- __Caso 1__: El valor de la lectura del contador es negativo \n",
    "    - __Caso 1a__: El valor del consumo calculado es positivo: se sustituye en el real\n",
    "    - __Caso 1b__: El valor del consumo calculado es negativo: se restringe a cero el valor real para no tener valores negativos\n",
    "- __Caso 2__ : El valor de la lectura del contador y el calculado son -1.00: se restringen a cero para no tener valores negativos  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Caso 2\n",
    "df_consumos.loc[(df_consumos['consumo_real']==-1.00) & (df_consumos['consumo_calculado']==-1.00), 'consumo_real'] = 0.00\n",
    "df_consumos.loc[(df_consumos['consumo_real']==-1.00) & (df_consumos['consumo_calculado']==-1.00), 'consumo_calculado'] = 0.00\n",
    "\n",
    "# Caso 1b\n",
    "df_consumos['consumo_real'] = np.where((df_consumos['consumo_real']<0) & (df_consumos['consumo_calculado']>0),\n",
    "df_consumos['consumo_calculado'], df_consumos['consumo_real'])\n",
    "\n",
    "# Caso 1a\n",
    "df_consumos.loc[(df_consumos['consumo_real']<0), 'consumo_real'] = 0.00"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_cajamar = pd.merge(df_meteo, df_consumos[['Date', 'ID', 'consumo_real', 'consumo_calculado']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = go.Figure()\n",
    "# add line / trace 1 to figure: Temperatura\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_cajamar['Date'],\n",
    "    y=df_cajamar['Temp.'],\n",
    "    marker=dict(\n",
    "        color=\"blue\"\n",
    "    ),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# add line / trace 2 to figure: Precipitaciones\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_cajamar['Date'],\n",
    "    y=df_cajamar['Precip.'],\n",
    "    marker=dict(\n",
    "        color=\"green\"\n",
    "    ),\n",
    "    showlegend=False\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_cajamar['Date'],\n",
    "    y=df_cajamar['consumo_real'],\n",
    "    marker=dict(\n",
    "        color=\"yellow\"\n",
    "    ),\n",
    "    showlegend=False\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Distribución de la temperatura y las precipitaciones\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Precipitaciones y temperatura\"\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Grafica del consumo real haciendo la suma de todas las estaciones de medida. \n",
    "# Haciendo la media queda la misma grafica casi y con la mediana se estabiliza todo pero no tiene mucho sentido aplicar la mediana\n",
    "df = df_cajamar.groupby(['Date'])['consumo_real'].sum().reset_index()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['Date'],\n",
    "    y=df['consumo_real'],\n",
    "    marker=dict(\n",
    "        color=\"yellow\"\n",
    "    ),\n",
    "    showlegend=False\n",
    "))\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering:\n",
    "\n",
    "Ejercicios de agrupación de estaciones para ver cuales son las más similares entre ellas en consumo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clusters = df_cajamar.groupby(['ID'])['consumo_real'].sum().reset_index()\n",
    "fig = px.histogram(clusters, x=\"consumo_real\")\n",
    "fig.show()\n",
    "\n",
    "# Hay 3 grupos claros de tipos de contadores:\n",
    "     # 0-100K, 100K-300K, >300K\n",
    "# Donde el grupo mayoritario es el primero y se podría segmentar en varios grupos "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clusters['Cluster'] = np.where(\n",
    "    clusters['consumo_real']<1e5,'1', \n",
    "        np.where((clusters['consumo_real']>=1e5)&(clusters['consumo_real']>=3e5), '2','3')\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster1 = clusters[clusters['Cluster']=='1']['ID'].tolist()\n",
    "cluster2 = clusters[clusters['Cluster']=='2']['ID'].tolist()\n",
    "\n",
    "df_cajamar['Cluster'] = np.where(\n",
    "    df_cajamar['ID'].isin(cluster1),'1', \n",
    "        np.where(df_cajamar['ID'].isin(cluster2), '2','3')\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Corrección de outliers con Kats\n",
    "Uso la libreria Kats para detectar outliers y para ver la estacionalidad de la serie.\n",
    "Se analiza por separado cada cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_cluster1 = df_cajamar[df_cajamar['Cluster']=='1'].groupby(['Date'])['consumo_real'].sum().reset_index()\n",
    "df_cluster2 = df_cajamar[df_cajamar['Cluster']=='2'].groupby(['Date'])['consumo_real'].sum().reset_index()\n",
    "df_cluster3 = df_cajamar[df_cajamar['Cluster']=='3'].groupby(['Date'])['consumo_real'].sum().reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from kats.utils.decomposition import TimeSeriesDecomposition\n",
    "from kats.detectors.outlier import OutlierDetector\n",
    "from kats.consts import TimeSeriesData\n",
    "\n",
    "def create_ts(df: pd.DataFrame):\n",
    "    # Construct TimeSeriesData object\n",
    "    df = df[['Date','consumo_real']]\n",
    "    df = df.rename(columns={\"Date\": \"time\", \"consumo_calculado\": \"value\"})\n",
    "    ts = TimeSeriesData(df)\n",
    "    return ts\n",
    "\n",
    "def get_outliers(ts):\n",
    "    outlier_detector = OutlierDetector(ts, \"additive\")\n",
    "    outlier_detector.detector()\n",
    "    outliers = outlier_detector.outliers\n",
    "    ts_outliers = outlier_detector.remover(interpolate=True)\n",
    "    print(outliers[0])\n",
    "    return ts_outliers\n",
    "\n",
    "def graph_wo_outliers(ts, ts_outliers):\n",
    "    ax = ts.to_dataframe().plot(x=\"time\", y=\"value\")\n",
    "    ts_outliers.to_dataframe().plot(x=\"time\", y=\"y_0\", ax=ax)\n",
    "    plt.legend(labels=[\"original ts\", \"ts with removed outliers\"])\n",
    "    print(plt.show())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ts1 = create_ts(df_cluster1)\n",
    "ts2 = create_ts(df_cluster2)\n",
    "ts3 = create_ts(df_cluster3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ts1_wo = get_outliers(ts1).to_dataframe()\n",
    "ts2_wo = get_outliers(ts2).to_dataframe()\n",
    "ts3_wo = get_outliers(ts3).to_dataframe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ts1_wo['Cluster'] = 1\n",
    "ts2_wo['Cluster'] = 2\n",
    "ts3_wo['Cluster'] = 3\n",
    "df_preprocesed = pd.concat([ts1_wo, ts2_wo, ts3_wo], axis=0)\n",
    "df_preprocesed.to_csv('inputs/Cajamar.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualización de los clusters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df_cajamar.groupby(['Date', 'Cluster'])['consumo_real'].sum().reset_index()\n",
    "fig = px.line(df,\n",
    "    x='Date',\n",
    "    y='consumo_real',\n",
    "    color='Cluster'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Quitando el cluster 2 que tiene valores mucho mas elevados. Los otros dos clusters tienen valores muy similares con un offset de un 40K"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlaciones entre variables\n",
    "Se analiza la correlación de las variables de temperatura y precipitación con la variable objetivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_preprocesed.columns = ['Date', 'consumo_real', 'Cluster']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_total = pd.merge(df_meteo, df_preprocesed, on='Date', how='inner')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "mask = np.triu(np.ones_like(df_total.corr(), dtype=bool))\n",
    "sns.heatmap(df_total.corr(),  annot=True, cmap='Dark2')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}